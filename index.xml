<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Depth 2 on ZDoc</title>
    <link>http://example.org/</link>
    <description>Recent content in Depth 2 on ZDoc</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&amp;copy;{year}, All Rights Reserved</copyright>
    <lastBuildDate>Fri, 28 Feb 2020 10:08:56 +0900</lastBuildDate>
    
        <atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml" />
    
    
    
      
      <item>
        <title>May 2019</title>
        <link>http://example.org/updates/2019_may/</link>
        <pubDate>Tue, 28 Jan 2020 00:10:51 +0900</pubDate>
        
        <guid>http://example.org/updates/2019_may/</guid>
        <description>Markdown here</description>
      </item>
      
      <item>
        <title>April 2019</title>
        <link>http://example.org/updates/2019_april/</link>
        <pubDate>Tue, 28 Jan 2020 00:10:48 +0900</pubDate>
        
        <guid>http://example.org/updates/2019_april/</guid>
        <description>Markdown here</description>
      </item>
      
      <item>
        <title>March 2019</title>
        <link>http://example.org/updates/2019_march/</link>
        <pubDate>Tue, 28 Jan 2020 00:10:42 +0900</pubDate>
        
        <guid>http://example.org/updates/2019_march/</guid>
        <description>Markdown here</description>
      </item>
      
      <item>
        <title>February 2019</title>
        <link>http://example.org/updates/2019_february/</link>
        <pubDate>Tue, 28 Jan 2020 00:10:37 +0900</pubDate>
        
        <guid>http://example.org/updates/2019_february/</guid>
        <description>Markdown here</description>
      </item>
      
      <item>
        <title>January 2019</title>
        <link>http://example.org/updates/2019_january/</link>
        <pubDate>Tue, 28 Jan 2020 00:10:09 +0900</pubDate>
        
        <guid>http://example.org/updates/2019_january/</guid>
        <description>Markdown here</description>
      </item>
      
      <item>
        <title>Central Tendency</title>
        <link>http://example.org/handbook/a-statistics/1-central-tendency/</link>
        <pubDate>Thu, 30 Jan 2020 00:38:25 +0900</pubDate>
        
        <guid>http://example.org/handbook/a-statistics/1-central-tendency/</guid>
        <description>Measures of Central Tendency Mean The sum total of units divided by the number of units. Average
μ (population) | x̄ (sample) | 1/ni=1nxi
Median The middle / midpoint value in a sorted sequence. Middle
It divides the data 50(more):50(less).
Mode The most commonly occurring value Frequent
Two modes = Bimodal ; Multiple modes = Multimodal
 Q) Why do we use mean most times ? A) It takes all values into consideration.</description>
      </item>
      
      <item>
        <title>Dispersion/Spread</title>
        <link>http://example.org/handbook/a-statistics/2-dispersion-spread/</link>
        <pubDate>Thu, 30 Jan 2020 00:38:25 +0900</pubDate>
        
        <guid>http://example.org/handbook/a-statistics/2-dispersion-spread/</guid>
        <description>Measures of Dispersion/Spread    Name Spread     Range Max - Min value   Percentile Divides the data into 100 equal parts using 99 points   Decile Divides the data into 10 equal parts using 9 points   Quartile Divides the data into 4 equal parts using 3 points (25%, 50%, 75%) Median is the 2nd quartile (50%) . Interquartile range : 25% - 75%    ℹ Boxplot uses a limit of 1.</description>
      </item>
      
      <item>
        <title>Markdown Syntax Guide</title>
        <link>http://example.org/blog/markdown-syntax/</link>
        <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/blog/markdown-syntax/</guid>
        <description>&lt;p&gt;Lorem est tota propiore conpellat pectoribus de&lt;br /&gt;
pectora summo. Redit teque digerit hominumque toris verebor lumina non cervice&lt;br /&gt;
subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc&lt;br /&gt;
caluere tempus&lt;/p&gt;</description>
      </item>
      
      <item>
        <title>Rich Content</title>
        <link>http://example.org/blog/rich-content/</link>
        <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/blog/rich-content/</guid>
        <description>&lt;p&gt;Lorem est tota propiore conpellat pectoribus de&lt;br /&gt;
pectora summo. Redit teque digerit hominumque toris verebor lumina non cervice&lt;br /&gt;
subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc&lt;br /&gt;
caluere tempus&lt;/p&gt;</description>
      </item>
      
      <item>
        <title>Placeholder Text</title>
        <link>http://example.org/blog/placeholder-text/</link>
        <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/blog/placeholder-text/</guid>
        <description>&lt;p&gt;Lorem est tota propiore conpellat pectoribus de&lt;br /&gt;
pectora summo. Redit teque digerit hominumque toris verebor lumina non cervice&lt;br /&gt;
subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc&lt;br /&gt;
caluere tempus&lt;/p&gt;</description>
      </item>
      
      <item>
        <title>Emoji Support</title>
        <link>http://example.org/blog/emoji-support/</link>
        <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/blog/emoji-support/</guid>
        <description>&lt;p&gt;Lorem est tota propiore conpellat pectoribus de&lt;br /&gt;
pectora summo. Redit teque digerit hominumque toris verebor lumina non cervice&lt;br /&gt;
subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc&lt;br /&gt;
caluere tempus&lt;/p&gt;</description>
      </item>
      
      <item>
        <title>Classification</title>
        <link>http://example.org/handbook/b-supervised-learning/2-classification/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/b-supervised-learning/2-classification/</guid>
        <description>﻿# Classification</description>
      </item>
      
      <item>
        <title>Clustering</title>
        <link>http://example.org/handbook/c-unsupervised-learning/clustering/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/c-unsupervised-learning/clustering/</guid>
        <description>Clustering Clustering Is a set of data driven partitioning techniques designed to group a collection of objects into clusters.
⚠️ Data should ALWAYS be continuous and standardized in nature.
✴ Clustering is finding borders between groups
✴ Segmentation is using borders to form groups
Applications :  Market Segmentation Sales segmentation : what type of customer wants what Credit risk Operations : High performing persons and promotions Insurance : identifying groups with high average claim cost Data reduction : grouping observations to reduce number is obs   How to build clusters :  Select distance measure Select clustering algorithm Define the distance between 2 clusters Determine no of clusters Validate the analysis  Methods  Linkage method Variance method Centroid method  Closeness of two clusters : The decision of merging two clusters is taken on the basis of closeness of these clusters.</description>
      </item>
      
      <item>
        <title>Covariance &amp; Correlation</title>
        <link>http://example.org/handbook/a-statistics/4-covariance-correlation/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/a-statistics/4-covariance-correlation/</guid>
        <description>Covariance &amp;amp; Correlation Correlation is a statistical technique that can show whether and how strongly pairs of variables are related. For example, height and weight are related; taller people tend to be heavier than shorter people.
⚠️ Correlation doesn&amp;rsquo;t imply causation
 Covariance : Covariance is nothing but a measure of correlation. On the contrary, correlation refers to the scaled form of covariance.
Returns a value between -∞ &amp;amp; +∞</description>
      </item>
      
      <item>
        <title>Distributions</title>
        <link>http://example.org/handbook/a-statistics/3-distributions/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/a-statistics/3-distributions/</guid>
        <description>Distributions Normal / Gaussian / Continuous Distribution data distributed symmetrically around the center skewness = kurtosis = 0. Mean = Median = Mode. Also known as the bell curve.
Binomial Distribution Discrete distribution used in statistics. Only counts 2 states typically 0 and 1.
Uniform Distribution Consists of similar values throughout
Skewed Distribution Data distributed which spikes towards either ends as opposed to the central spike in normal distribution (skewness: lack of symmetry)</description>
      </item>
      
      <item>
        <title>Ensemble Learning</title>
        <link>http://example.org/handbook/b-supervised-learning/3-ensemble/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/b-supervised-learning/3-ensemble/</guid>
        <description>﻿# Ensemble Learning
Ensemble model combines multiple ‘individual’ (diverse) models together and delivers superior prediction power. A good model should maintain a balance between bias-variance. This is known as the trade-off management of bias-variance errors. Ensemble learning is one way to execute this trade off analysis.
**Bagging :**Bagging is an approach where you take random samples of data, build learning algorithms and take simple means to find bagging probabilities.Objective is to average noisy and unbiased models to create a model with low variance</description>
      </item>
      
      <item>
        <title>Hypothesis Testing</title>
        <link>http://example.org/handbook/a-statistics/5-hypothesis-testing/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/a-statistics/5-hypothesis-testing/</guid>
        <description>Hypothesis Testing  Null Hypothesis  H0 : μ1 = μ2x 
The means of the two groups (μ1 &amp;amp; μ2) belong to the same population. (p &amp;gt; 0.05)
 Alternative Hypothesis  HA : μ1 ≠ μ2
The means of the two groups (μ1 &amp;amp; μ2) belong to different populations. In case of multiple groups, the mean of all groups shouldn’t be the same. At least one group should be different.</description>
      </item>
      
      <item>
        <title>KNN</title>
        <link>http://example.org/handbook/c-unsupervised-learning/knn-k-nearest-neighbors/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/c-unsupervised-learning/knn-k-nearest-neighbors/</guid>
        <description>KNN (K- Nearest Neighbors) It is a simple algorithm which classifies cases based on its votes by its nearest neighbors whose class is already known. The “K” is KNN algorithm is the number of nearest neighbors we wish to take vote from. The class to be chosen depends on a distance function.
Categorical : Euclidean, Manhattan, Minkowski
Continuous : Hamming
Advantages:  Attributes with multiple missing values can be easily treated Can predict both qualitative &amp;amp; quantitative (by taking average) attributes Easy interpretation.</description>
      </item>
      
      <item>
        <title>Knowledge Repository</title>
        <link>http://example.org/handbook/need-to-know/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/need-to-know/</guid>
        <description>The Important Stuff Everyone Misses!   Multivariate Analysis is nothing but regression
  Logistic regression IS a binomial regression (with logit link), a special case of the Generalized Linear Model. It doesn&amp;rsquo;t classify anything unless a threshold for the probability is set. Classification is just its application.
  Stepwise regression is by no means a regression. It&amp;rsquo;s a (flawed) method of variable selection.
  OLS is a method of estimation (among others: GLS, TLS, (RE)ML, PQL, etc.</description>
      </item>
      
      <item>
        <title>NLP</title>
        <link>http://example.org/handbook/nlp/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/nlp/</guid>
        <description>Natural Language Processing NLP can be divided in supervised and unsupervised techniques
 Supervised:  Text Classification (Spam Recognition, labeling, etc) Spam Detection Sentiment Analysis Intent Classification Multi-Label, Multi-Class Text Classification   Unsupervised: Topic Modeling  Applications
 Sentiment Analysis Speech Recognition Chatbot Machine Translation (Google Translate) Spell Checking Keyword Search Information Extraction Advertisement Matching  NLU - Natural Language Understanding  Mapping input to useful representations Analyzing different aspects of the language  NLG - Natural Language Generation  Text planning Sentence planning Text realization  Ambiguities  Lexical Ambiguity - Two or more possible meanings in a word.</description>
      </item>
      
      <item>
        <title>Regression</title>
        <link>http://example.org/handbook/b-supervised-learning/1-regression/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/b-supervised-learning/1-regression/</guid>
        <description>Regression {:toc}
Regression analysis is a statistical process for estimating the relationships among variables.
Correlation only measures the strength of a linear relationship, it doesn’t tell anything regarding the relationship.
Regression is used to figure out the relationship itself.
 Eg: if correlation between Y and X is 0.7 then it says if X increases, 70% of the time Y increases. But regression tells if X increases by 1 unit, by how many units does Y increase.</description>
      </item>
      
      <item>
        <title>Reinforcement Learning</title>
        <link>http://example.org/handbook/d-reinforcement-learning/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/d-reinforcement-learning/</guid>
        <description>Reinforcement Learning </description>
      </item>
      
      <item>
        <title>Statistical Tests</title>
        <link>http://example.org/handbook/a-statistics/6-statistical-tests/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/a-statistics/6-statistical-tests/</guid>
        <description>Statistical Tests Parametric Test : used for normally distributed data (assess group means)
Non-Parametric Test : used for skewed data (assess group medians)
One Tailed : uni-directional (typing speed increases with more typing) Two tailed: bi-directional (typing speed can increase or decrease with more typing)
P-value is the probability of the sample means coming up equal to or even further away from the hypothesized population mean.
z-Test (sample size &amp;gt; 30) Statistical calculation used to compare sample mean to population mean.</description>
      </item>
      
      <item>
        <title>SVD</title>
        <link>http://example.org/handbook/c-unsupervised-learning/singular-value-decomposition/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/c-unsupervised-learning/singular-value-decomposition/</guid>
        <description>Singular Value Decomposition </description>
      </item>
      
      <item>
        <title>Time Series / Forecasting</title>
        <link>http://example.org/handbook/b-supervised-learning/time-series-forecasting/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/b-supervised-learning/time-series-forecasting/</guid>
        <description>Time Series (Forecasting) [Method = Box-Jenkins (B-J)] Components Trend : A long term (relatively smooth) pattern that usually persists for more than one year
Eg : increasing no of flight passengers
Seasonal : Pattern that occurs at regular intervals. [multiple times in a year (least is once a year)]
Eg December sale
Cyclical : Pattern that occurs over a long time, generally continues over a year
Eg : Recession
Random : The component obtained after the above patterns have been extracted.</description>
      </item>
      
      <item>
        <title>☑️ Model Evaluation</title>
        <link>http://example.org/handbook/b-supervised-learning/model-evaluation/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://example.org/handbook/b-supervised-learning/model-evaluation/</guid>
        <description>Model Evaluation / Selection / Fits / Validation Train Test Split  Before running the model, the data is split into Training and Testing sets. The training to test split ratio is generally 70:30 and can vary. The model is trained on the Training dataset hence the name Once the model is fit on the data, we use the Testing dataset to check how the model performs.  The model is best served with a k-fold cross validation set where the data is randomly split multiple k times and each time the model fit is checked.</description>
      </item>
      
    
  </channel>
</rss>