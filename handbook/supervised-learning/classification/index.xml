<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Classification on TMLHB</title><link>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/</link><description>Recent content in Classification on TMLHB</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&amp;copy;{year}, All Rights Reserved</copyright><lastBuildDate>Wed, 21 Oct 2020 06:14:22 +0900</lastBuildDate><atom:link href="https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/index.xml" rel="self" type="application/rss+xml"/><item><title>Logistic Regression</title><link>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/1-logistic-regression/</link><pubDate>Wed, 21 Oct 2020 06:14:22 +0900</pubDate><guid>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/1-logistic-regression/</guid><description>Logistic Regression Although Logistic Regression is termed a Regression, it is in fact a method of Classification. The underlying methodology utilized concepts to linear regression and hence the name sayed.
Method = Maximum Likelihood Estimation / Chi-square
Logistic Regression is used to model the probability of an outcome. It is based on concept of Generalized Linear Model (GLM).
Dependent Variable Y = Binary (eg 0 or 1)
Independent Variable X = Continuous or Categorical</description></item><item><title>Decision Trees</title><link>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/2-decision-trees/</link><pubDate>Sat, 03 Apr 2021 18:30:00 +0000</pubDate><guid>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/2-decision-trees/</guid><description>Decision Trees It&amp;rsquo;s a type of supervised learning algorithm mostly used for classification problems. Works for both categorical and continuous I/P O/P variables.
The population is split into two or more homogeneous sets based on the splitting criterion.
Analogy : They ask a bunch of questions to arrive at a particular answer. (20 Questions)
Types :
Categorical Variable Decision Tree : Categorical Target Variable Continuous Variable Decision Tree : Continuous Target Variable Terminology : Root Node : It represents the entire population / sample Parent and Child Node: A node, which is divided into sub-nodes is called parent node whereas sub-nodes are the child of parent node.</description></item><item><title>Support Vector Machine</title><link>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/3-support-vector-machine/</link><pubDate>Sat, 03 Apr 2021 18:30:00 +0000</pubDate><guid>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/3-support-vector-machine/</guid><description>SVM (Support Vector Machine) ![](https://lh5.googleusercontent.com/n0CPoXbAgg0MNx5jxNNmn14h-aWrPgVDUj4uo_6DqnUL4iRX7ZHTjl8GoDwXn1IWbp1743NgaDXva8rDUtac5oKaPdAZMbJ4qaOqNx23JVCZHwEOwyeLdizmFHJG57oHKNidmboV =308x209)
In this algorithm, each data item is plotted as a point in n-dimensional space (where n is the number of features you have) with the value of each feature being the value of a particular coordinate.
The aim is to determine the location of decision boundaries also known as hyperplane that produce the optimal separation of classes. Multiple frontiers are produced to suit the data.</description></item><item><title>Naive Bayes</title><link>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/4-na%C3%AFve-bayes/</link><pubDate>Sat, 03 Apr 2021 18:30:00 +0000</pubDate><guid>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/4-na%C3%AFve-bayes/</guid><description>Naïve Bayes It is a classification technique based on Bayes’ theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. P(c|x) is the posterior probability of class (target) given predictor (attribute). P(c) is the prior probability of class. P(x|c) is the likelihood which is the probability of predictor given class.</description></item><item><title>Artificial Neural Network</title><link>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/5-artificial-neural-network/</link><pubDate>Sat, 03 Apr 2021 18:30:00 +0000</pubDate><guid>https://do2blehelix.github.io/the-ml-handbook/handbook/supervised-learning/classification/5-artificial-neural-network/</guid><description>Artificial Neural Network (ANN) Artificial neural networks (ANNs) are types of computer architecture inspired by biological neural networks (Nervous systems of the brain) and are used to approximate functions that can depend on a large number of inputs and are generally unknown. Artificial neural networks are presented as systems of interconnected “neurons” which can compute values from inputs and are capable of machine learning as well as pattern recognition due their adaptive natureAn artificial neural network operates by creating connections between many different processing elements each corresponding to a single neuron in a biological brain.</description></item></channel></rss>